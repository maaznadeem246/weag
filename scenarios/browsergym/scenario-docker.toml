# Docker Scenario for kickstart_assessment.py
# Use this when running with Docker containers (no local process spawning)
#
# USAGE:
#   .\docker-test.ps1 -Start                           # Start containers first
#   python kickstart_assessment.py --scenario scenarios/browsergym/scenario-docker.toml --task miniwob.click-test
#
# This config connects to existing Docker containers instead of spawning processes

# =============================================================================
# ASSESSMENT SETTINGS
# =============================================================================
[assessment]
# Default timeout for the whole assessment run (seconds)
timeout_seconds = 120
# Default max steps per task (passed to Green; actual enforcement depends on benchmark/env)
max_steps = 10
# Default max tasks per benchmark (used when benchmark doesn't specify max_tasks)
max_tasks_per_benchmark = 2
# Browser visibility (set to false for headless)
headless = true

# =============================================================================
# GREEN AGENT (Evaluator) - Docker Container
# =============================================================================
[green_agent]
endpoint = "http://localhost:9009"
# NO 'cmd' field - connects to existing Docker container on port 9009

# Purple agent URL for Docker networking (green->purple communication)
# Inside Docker, containers use service names, not localhost
# purple_agent_url = "http://purple-agent:9010/"

# Optional: env vars (already set in docker-compose.yml, these are for reference only)
[green_agent.env]
# GREEN_LLM_PROVIDER = "openai"
# GREEN_OPENAI_MODEL = "gpt-4"
# Set via .env file

# =============================================================================
# PURPLE AGENT (Participant) - Docker Container
# =============================================================================
[[participants]]
role = "purple_agent"
# Docker networking: Green Agent reaches Purple Agent via container name, not localhost
# This is the endpoint Green Agent uses to communicate with Purple Agent inside Docker network
endpoint = "http://purple-agent:9010/"
# NO 'cmd' field - connects to existing Docker container on port 9010

# Optional: env vars (already set in docker-compose.yml, these are for reference only)
[purple_agent.env]
# PURPLE_LLM_PROVIDER = "openai"
# PURPLE_OPENAI_MODEL = "gpt-4"
# Set via .env file

# =============================================================================
# BENCHMARKS CONFIGURATION
# =============================================================================
# Each [[benchmarks]] section defines a benchmark to evaluate.
# 
# Options:
#   id        - Benchmark identifier (miniwob, assistantbench, webarena, etc.)
#   max_tasks - Max tasks to run for THIS benchmark (overrides global max_tasks_per_benchmark)
#   tasks     - OPTIONAL explicit task list. If OMITTED, auto-discovers available tasks!
#
# AUTO-DISCOVERY MODE (RECOMMENDED):
#   Simply omit the `tasks` line - system will find all available tasks and limit by max_tasks
#
# SUPPORTED BENCHMARKS:
#   - miniwob: Requires local dataset at benchmarks/miniwob/html/miniwob/
#   - assistantbench: Auto-downloads from HuggingFace (no setup needed)
#   - webarena: Requires Docker containers (WA_* env vars)
#   - visualwebarena: Requires Docker containers (VWA_* env vars)
#   - workarena: Requires ServiceNow dev instance (WORKARENA_* env vars)
#   - weblinx: Requires dataset download (WEBLINX_DATA_PATH env var)

# MiniWoB - Local HTML tasks (ready to use)
# [[benchmarks]]
# id = "miniwob"
# Uses global max_tasks_per_benchmark

# AssistantBench - HuggingFace tasks (ready to use)
# [[benchmarks]]
# id = "assistantbench"

# WebArena - Requires Docker setup (comment out if not available)
# [[benchmarks]]
# id = "webarena"
# max_tasks = 3

# VisualWebArena - Requires Docker setup (comment out if not available)
# [[benchmarks]]
# id = "visualwebarena"
# max_tasks = 3

# WorkArena - Requires ServiceNow instance (comment out if not available)
# [[benchmarks]]
# id = "workarena"
# max_tasks = 3

# WebLINX - Requires dataset download (comment out if not available)
# [[benchmarks]]
# id = "weblinx"
# max_tasks = 3

# EXPLICIT MODE EXAMPLE (uncomment to use specific tasks):
# [[benchmarks]]
# id = "miniwob"
# tasks = ["click-test", "ascending-numbers", "book-flight"]
